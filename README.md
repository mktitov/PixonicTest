# PixonicTest
> 1 Есть данные которые превышают объем оперативной памяти. Необходимо отсортировать (пойдет даже текстовое описание, саму программу не обязательно писать)

1. Режем файл на сегменты размером достаточным для обработки в оперативной памяти
2. Каждый сегмент отдельно сортируем и сбрасываем отсортированные данные в файл. 
  * На выходе, для каждого сегмента, получим файл с отсортированными данными
  * Сортировку бы использовал пузырьковую 
  * Процесс чтения сегмента и сортировки сделал бы асинхронными
  * Если не использовать параллельную сортировку, тогда тогда сегменты можно обрабатывать с уровнем парализации по кол-ву ядер
3. После сортировки всех сегментов, начинаем сборку результирующего файла:
  1. Считываем по записи с каждого сегмента
  2. Находим наименьшую с точки зрения сортировки
  3. Сохраняем в результирующий файл
  4. Подгружаем запись для сегмента с которого была взята запись
  5. Переходим в пункт 2
  
Если еще и озаботиться рапределением сегментов по разным хостам было бы эффективнней, но для решения подобных задач есть hadoop (HDFS) + (MapReduce || Spark)  

> 2 На вход поступают пары (DateTime, Callable). Нужно реализовать систему, которая будет выполнять Callable для каждого пришедшего события в указанный DateTime, либо как можно скорее в случае если система перегружена и не успевает все выполнять (имеет беклог). Задачи должны выполняться в порядке согласно значению, DateTime либо в порядке прихода события для равных DateTime. События могут приходить в произвольном порядке и добавление новых пар (DateTime, Callable) может вызываться из разных потоков.
Решения можно оформить в любом удобном виде: проект на гитхабе, архив с исходным кодом и т.п. Можно использовать любые встроенные средства Java7/Java8....

Возможно не совсем понял задачу (может необходимо гарантировать выполнение задач после сбоя или, опять же, учитывать тот факт что не все они могут поместиться в RAM)..., поскольку для решения подобной задачи в Java (с версии 1.5) есть  java.util.concurrent.ScheduledThreadPoolExecutor.

В своем проекте (RAVEN) для решения подоюной задачи использую связку (ThreadedPoolExecutor | ForkJoinPool) + DelayQueue

Тем не менее:

1. Делаем clone|download проекта
2. mvn test
